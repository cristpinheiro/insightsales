"""
Ollama service for LLM interactions.

Handles communication with Ollama API for text-to-SQL generation
and result explanations.
"""

import httpx
from app.core.config import settings


class OllamaService:
    """Service for interacting with Ollama LLM API."""

    def __init__(self):
        self.base_url = settings.OLLAMA_BASE_URL
        self.model = settings.OLLAMA_MODEL
        self.timeout = settings.OLLAMA_TIMEOUT

    async def generate_sql(self, question: str, schema_context: str) -> dict:
        """Generate SQL query from natural language question."""
        prompt = f"{schema_context}\n\nQuestion: {question}"

        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.base_url}/api/generate",
                    json={
                        "model": self.model,
                        "prompt": prompt,
                        "stream": False,
                    },
                )
                response.raise_for_status()
                result = response.json()

                sql = result.get("response", "").strip()

                return {
                    "sql": sql,
                    "explanation": "SQL query generated by model",
                    "error": None,
                }

        except httpx.TimeoutException:
            return {
                "sql": None,
                "explanation": "Timeout connecting to Ollama. Check if the service is running.",
                "error": "timeout",
            }
        except httpx.HTTPError as e:
            return {
                "sql": None,
                "explanation": f"Error communicating with Ollama: {str(e)}",
                "error": "http_error",
            }
        except Exception as e:
            return {
                "sql": None,
                "explanation": f"Unexpected error: {str(e)}",
                "error": "unknown",
            }

    async def explain_results(self, question: str, sql: str, results: list) -> str:
        """Generate natural language explanation of query results."""
        prompt = self._build_explanation_prompt(question, sql, results)

        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.base_url}/api/generate",
                    json={
                        "model": self.model,
                        "prompt": prompt,
                        "stream": False,
                    },
                )
                response.raise_for_status()
                result = response.json()

                return result.get("response", "Could not generate explanation.")

        except Exception as e:
            return f"Error generating explanation: {str(e)}"

    def _build_explanation_prompt(self, question: str, sql: str, results: list) -> str:
        """Build prompt for result explanation."""
        results_summary = f"Found {len(results)} result(s)"
        if results:
            results_summary += f": {results[:3]}"

        return f"SQL Query: {sql}\nResults: {results_summary}\n\nExplain the results in relation to the question: {question}"
